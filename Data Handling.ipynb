{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling With Pandas\n",
    "\n",
    "## Introduction\n",
    "Pandas is built on numpy and can be used to interepet data. This notebook is used to maintain the collection of all useful tasks that can be performed with Pandas\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'data/example_data/data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Inference and Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first few rows\n",
    "data.head(n=2) # default is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe on csv data gives count, mean, variance and other statistical details about each parameter in the input \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List parameters(columns)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the data type of each input parameter\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added info on input parameters\n",
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing data by parameter\n",
    "data['Customer Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting statistical values by paramter\n",
    "data.Year.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion using astype\n",
    "data['Customer Number'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work as the values(like 15,000.00$) are not stright forward integeres\n",
    "try:\n",
    "    data['2016'].astype('float')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work as one of the values is 'Closed' (not a number)\n",
    "try:\n",
    "    data['Jan Units'].astype('int')\n",
    "except Exception as  e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work as expected as it can't interpret from Y/N\n",
    "data['Active'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using to_numeric to convert to int\n",
    "# coerce sets errored instance to NaN\n",
    "pd.to_numeric(data['Jan Units'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting errored values to zero\n",
    "pd.to_numeric(data['Jan Units'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using to_datatime to generate date from individual parameters\n",
    "pd.to_datetime(data[['Month', 'Day', 'Year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Useful Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a convertor function and apply to change currency to int\n",
    "def convertor(value):\n",
    "    result = value.replace(',','').replace('$','')\n",
    "    return float(result)\n",
    "\n",
    "data['2016'].apply(convertor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lambdas and apply to change currency to int\n",
    "data['2016'].apply(lambda x : x.replace(',','').replace('$','')).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where acts like if clause\n",
    "np.where(data['Active'] == \"Y\", True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna is used to drop rows or columns with na.\n",
    "# axis = 0 - rows with na are dropped\n",
    "# axis = 1 - columns with na are dropped\n",
    "pd.to_numeric(data['Jan Units'], errors='coerce').dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell shows how to pick few necessary columns from input data\n",
    "data[['Customer Number', '2016', 'Active']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this way a new dataframe can be initialized.\n",
    "result = pd.DataFrame({'Number': data['Customer Number'],\n",
    "                     'Active' : data['Active']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe can be output to csvfile\n",
    "result.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(file_path,\n",
    "                   dtype={'Customer Number': 'int'},\n",
    "                   converters={'2016': convertor,\n",
    "                               '2017': convertor,\n",
    "                               'Percent Growth': lambda x : float(x.replace('%',''))/100,\n",
    "                               'Jan Units': lambda x: pd.to_numeric(x, errors='coerce'),\n",
    "                               'Active': lambda x: np.where(x == \"Y\", True, False)\n",
    "                              })\n",
    "\n",
    "data2 = data2[['Customer Number', '2016', '2017', 'Percent Growth', 'Jan Units']]\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Values\n",
    "The data we work on generally comes with lot of missing values. The models we work with do not accommodate data with missing values. \n",
    "\n",
    "### Removing rows with missing values\n",
    "Removing rows with NaN or blanks is straight forward approach. If there are very few missing fields it can be simpler to use this with out loosing much of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As mentioned above dropna can be for this\n",
    "data2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with missing values\n",
    "Removing columns with missing values is much costlier as we would be forced to ignore a feature with missing values. This will be too costly if the feature plays strong role in prediction of target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are again going to use dropna to drop columns.\n",
    "data2.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "Imputation is replacing the missing values with simulated ones. The common pattern is to replace the missing value with average.\n",
    "Imputation is frequently used as it wouldn't result in discarding of data. There are frequent cases where models performed better with imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "my_imputer = Imputer()\n",
    "my_imputer.fit_transform(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation with indicator\n",
    "To better imputation is to relay the information about imputed values to model. Many models by scikit learn that support this. In many cases this helps models to be vary of making judgement based on imputed values.\n",
    "This generally done by adding new columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the values to new matrix\n",
    "data_copy = data2.copy()\n",
    "\n",
    "# Collect column names with missing values\n",
    "columns_with_missing_values = (col for col in data_copy.columns if data_copy[col].isnull().any())\n",
    "\n",
    "# Now for these colums create new columns which stores boolean values to indicate missing value.\n",
    "for col in columns_with_missing_values:\n",
    "    data_copy[col+'_was_missing'] = data_copy[col].isnull()\n",
    "    \n",
    "data_copy\n",
    "    \n",
    "# Now impute the missing values\n",
    "#my_imputer = Imputer()\n",
    "#my_imputer.fit_transform(data_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encodings\n",
    "Machine learning models aren't built to work on categorical data. We need to modify the input categorical data to match the input constraints of these models. One of the well known method is One Shot Encoding\n",
    "\n",
    "### One Shot Encoding\n",
    "One shot encoding is converting categorical values for feature to a set of boolean feature for each category. Say we have colors as feature then we will be converting it to multiple new feature as is_orange, is_red etc. \n",
    "As you have seen this isn't scalable but works. If category count is huge we just push all the minorities to a feature like 'is_others'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas get_dummies converts catogorical text to features with boolean values.\n",
    "pd.get_dummies(data[['Customer Number', 'Active']])\n",
    "\n",
    "# we need to have same ordering of columns in test and training data. can be done with align\n",
    "\n",
    "# join - left : preserves columns from left side and remove ones specific to right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* http://pbpython.com/pandas_dtypes.html\n",
    "* https://www.kaggle.com/dansbecker/explore-your-data\n",
    "* https://www.kaggle.com/dansbecker/your-first-machine-learning-model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
